# AZ-301T03 Module 2 Lab: Creating Managed Server Applications in Azure
# =====================================================================

# Exercise 1: Create Azure Kubernetes Service (AKS) cluster
# ---------------------------------------------------------

RESOURCE_GROUP='AADesignLab0402-RG'
echo $RESOURCE_GROUP

LOCATION='westeurope'
echo $LOCATION

az group create --name $RESOURCE_GROUP --location $LOCATION

az aks create \
    --resource-group $RESOURCE_GROUP \
    --name aad0402-akscluster \
    --node-count 1 \
    --node-vm-size Standard_F2s_v2 \
    --generate-ssh-keys

# Error: ... The credentials in ServicePrincipalProfile were invalid. ...
SP=$(az ad sp create-for-rbac --name "MyKubeCluster" --skip-assignment)
echo $SP

SP_appId=$(echo $SP | jq .appId | tr -d '""')
SP_password=$(echo $SP | jq .password | tr -d '""')

az aks create \
    --resource-group $RESOURCE_GROUP \
    --name Mein-kleiner-K8s-Cluster \
    --node-count 1 \
    --node-vm-size Standard_F2s_v2 \
    --generate-ssh-keys \
    --service-principal $SP_appId \
    --client-secret $SP_password


az aks list -o table

az aks get-credentials \
    --resource-group $RESOURCE_GROUP \
    --name aad0402-akscluster

kubectl config get-contexts
ls -l ~/.kube/config
cat ~/.kube/config

kubectl config current-context

kubectl get nodes
kubectl get pods
kubectl get deployment
kubectl get service

# Exercise 2: Managing an AKS cluster and its containerized workloads
# -------------------------------------------------------------------

kubectl run aad0402-akscluster --image=nginx --replicas=1 --port=80

kubectl get pods
kubectl get pods --all-namespaces

kubectl get deployment
kubectl expose deployment aad0402-akscluster --port=80 --type=LoadBalancer

kubectl get service --watch

kubectl scale --replicas=2 deployment/aad0402-akscluster
kubectl get pods

az aks scale \
    --resource-group $RESOURCE_GROUP \
    --name aad0402-akscluster \
    --node-count 2

kubectl get nodes

kubectl scale --replicas=10 deployment/aad0402-akscluster

kubectl get pods

kubectl get pod -o=custom-columns=NODE:.spec.nodeName,POD:.metadata.name

kubectl delete deployment aad0402-akscluster


# Exercise 3
# ----------

git clone https://github.com/Azure-Samples/azure-voting-app-redis.git

cd azure-voting-app-redis
cat azure-vote-all-in-one-redis.yaml
kubectl apply -f azure-vote-all-in-one-redis.yaml

kubectl get pods
kubectl get service azure-vote-front --watch

cd ~
git clone https://github.com/kubernetes-incubator/metrics-server.git

kubectl create -f ~/metrics-server/deploy/kubernetes

kubectl autoscale deployment azure-vote-front --cpu-percent=50 --min=3 --max=10

kubectl get hpa
kubectl get pods

kubectl delete deployment azure-vote-front
kubectl delete deployment azure-vote-back

kubectl get pods

# Enable Dashboard
kubectl create clusterrolebinding kubernetes-dashboard --clusterrole=cluster-admin --serviceaccount=kube-system:kubernetes-dashboard
az aks browse --resource-group AADesignLab0402-RG --name aad0402-akscluster

az aks delete --resource-group AADesignLab0402-RG --name aad0402-akscluster --yes --no-wait


# Exercise 4: Implement DevOps with AKS
# -------------------------------------
# Note: This solution is based on the DevOps with Containers solution described at 
# https://docs.microsoft.com/en-us/azure/architecture/example-scenario/apps/devops-with-aks


ssh-keygen -t rsa -b 2048

PUBLIC_KEY=$(cat ~/.ssh/id_rsa.pub)
PUBLIC_KEY_REGEX="$(echo $PUBLIC_KEY | sed -e 's/\\/\\\\/g; s/\//\\\//g; s/&/\\\&/g')"
echo $PUBLIC_KEY_REGEX

RESOURCE_GROUP='AADesignLab0403-RG'
LOCATION='eastus2'

az group create --name $RESOURCE_GROUP --location $LOCATION

SERVICE_PRINCIPAL=$(az ad sp create-for-rbac --name AADesignLab0403-SP  --output json)

APP_ID=$(echo $SERVICE_PRINCIPAL | jq .appId | tr -d '"')
echo $APP_ID

PASSWORD=$(echo $SERVICE_PRINCIPAL | jq -r .password)
echo $PASSWORD

# --- parameter.json ---
ll allfiles/AZ-301T03/Module_02/LabFiles/Starter/parameters.json
cp allfiles/AZ-301T03/Module_02/LabFiles/Starter/parameters.json ~/parameters.json
cat ~/parameters.json

sed -i.bak1 's/"$APP_ID"/"'"$APP_ID"'"/' ~/parameters.json
sed -i.bak2 's/"$PASSWORD"/"'"$PASSWORD"'"/' ~/parameters.json
sed -i.bak3 's/"$PUBLIC_KEY_REGEX"/"'"$PUBLIC_KEY_REGEX"'"/' ~/parameters.json

cat ~/parameters.json

az aks get-versions --location $LOCATION --output table
cat allfiles/AZ-301T03/Module_02/LabFiles/Starter/azuredeploy.json | jq .variables.kubernetesVersion | tr -d '"'

# ARM template from GitHub says 1.16.9
# Jenkins pipeline stage 4 fails with Kubernetes version 1.16.9
# Let's test other Kubernetes version!
# Problem: "kubernetesVersion" is not a parameter (it's a variable) in ARM template on GitHub
# Solution: clone GitHub repo (it's cloned already!)

# --- Original deployment - ARM template from GitHub repo
# az group deployment create \
#     --resource-group $RESOURCE_GROUP \
#     --template-uri https://raw.githubusercontent.com/MicrosoftLearning/AZ-301-MicrosoftAzureArchitectDesign/master/allfiles/AZ-301T03/Module_02/LabFiles/Starter/azuredeploy.json \
#     --parameters ~/parameters.json

# Kubernetes version    Jenkins pipeline (stage 4)
# ------------------    --------------------------
#   1.16.9                  fail
#   1.16.8                  fail
#   1.15.11                 success
#   1.14.7                  success

# --- New deployment - ARM template local file
cp allfiles/AZ-301T03/Module_02/LabFiles/Starter/azuredeploy.json ~/azuredeploy.json
#     Replace Kubernetes version
sed -i.bak1 's/"1.16.9"/"1.15.11"/g' ~/azuredeploy.json

az deployment group create \
    --resource-group $RESOURCE_GROUP \
    --template-file ~/azuredeploy.json \
    --parameters ~/parameters.json



# =========================
#        Follow up
# =========================
az resource list --resource-group $RESOURCE_GROUP -o table

# Jenkins
# -------
az vm list --show-details --resource-group $RESOURCE_GROUP --output table
jenkinsFqdn=$(az vm show --show-details --name jenkins --resource-group $RESOURCE_GROUP --query "fqdns" --output tsv)

# connect to Jenkis dashboard via ssh tunnel
jenkinsSSH=$(az deployment group show --name azuredeploy --resource-group $RESOURCE_GROUP --query "properties.outputs.jenkinsSSH.value" --output tsv)
$jenkinsSSH
# get Jenkins admin password
sudo cat /var/lib/jenkins/secrets/initialAdminPassword
# open in browser http://localhost:8080
# login to Jenkins dashboard with the admin password


# Registry
# --------
acrId=$(az resource list --resource-type Microsoft.ContainerRegistry/registries --resource-group $RESOURCE_GROUP --query "[].id" --output tsv)
acrName=$(az resource show --ids $acrId --query "name" --output tsv)

az acr repository list --name $acrName 
az acr repository show --name $acrName --repository hello-world 
az acr repository show --name $acrName --image hello-world:1


# Kubernetes
# ----------
aksName=$(az aks list --resource-group $RESOURCE_GROUP --query "[].name" --output tsv)
az aks get-credentials --name $aksName --resource-group $RESOURCE_GROUP

kubectl get deployments
kubectl get pods
kubectl get services
# record the public ip of "hello-world-service", open in browser


# Vnet (for VMs)
# --------------
vnetName="virtual-network"
# add Bastion for better connections
bastionSubnet="10.0.255.32/27"
az network vnet subnet create --name "AzureBastionSubnet" --address-prefixes $bastionSubnet --vnet-name $vnetName --resource-group $RESOURCE_GROUP
az network vnet subnet list --vnet-name $vnetName --resource-group $RESOURCE_GROUP --query "[].{name:name,addressPrefix:addressPrefix}" --output table
az network public-ip create --name "DevOpsBastionIp" --allocation-method Static --sku Standard --resource-group $RESOURCE_GROUP
az network bastion create --name "DevOpsBastion" --public-ip-address "DevOpsBastionIp" --vnet-name $vnetName --resource-group $RESOURCE_GROUP
az network bastion list --output table


# Clean up
# --------
az group delete --name $RESOURCE_GROUP --yes --no-wait
az ad sp delete --id $APP_ID
rm ~/parameters.json*
rm ~/azuredeploy.json*
ssh-keygen -R $jenkinsFqdn
kubectl config view
kubectl config delete-context $aksName
kubectl config delete-cluster $aksName
kubectl config unset users.clusterUser_AADesignLab0403-RG_$aksName

# $aksName
# 2. deployment  aksmytggs3hzesb6
# 3. deployment  aksmytggs3hzesb6